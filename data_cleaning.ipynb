{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk import pos_tag\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('Data/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                            0\n",
       "airline_sentiment                   0\n",
       "airline_sentiment_confidence        0\n",
       "negativereason                   5462\n",
       "negativereason_confidence        4118\n",
       "airline                             0\n",
       "airline_sentiment_gold          14600\n",
       "name                                0\n",
       "negativereason_gold             14608\n",
       "retweet_count                       0\n",
       "text                                0\n",
       "tweet_coord                     13621\n",
       "tweet_created                       0\n",
       "tweet_location                   4733\n",
       "user_timezone                    4820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Service Issue                      12\n",
       "Late Flight                                  4\n",
       "Cancelled Flight                             3\n",
       "Can't Tell                                   3\n",
       "Cancelled Flight\\nCustomer Service Issue     2\n",
       "Late Flight\\nCancelled Flight                1\n",
       "Late Flight\\nFlight Attendant Complaints     1\n",
       "Bad Flight                                   1\n",
       "Customer Service Issue\\nLost Luggage         1\n",
       "Lost Luggage\\nDamaged Luggage                1\n",
       "Flight Attendant Complaints                  1\n",
       "Late Flight\\nLost Luggage                    1\n",
       "Customer Service Issue\\nCan't Tell           1\n",
       "Name: negativereason_gold, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['negativereason_gold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    32\n",
       "positive     5\n",
       "neutral      3\n",
       "Name: airline_sentiment_gold, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['airline_sentiment_gold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     13873\n",
       "1       640\n",
       "2        66\n",
       "3        22\n",
       "4        17\n",
       "5         5\n",
       "7         3\n",
       "6         3\n",
       "22        2\n",
       "8         1\n",
       "32        1\n",
       "9         1\n",
       "31        1\n",
       "18        1\n",
       "15        1\n",
       "28        1\n",
       "44        1\n",
       "11        1\n",
       "Name: retweet_count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['retweet_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015-02-24 09:54:34 -0800    5\n",
       "2015-02-24 11:43:05 -0800    4\n",
       "2015-02-23 15:25:46 -0800    3\n",
       "2015-02-23 14:18:58 -0800    3\n",
       "2015-02-23 10:58:58 -0800    3\n",
       "                            ..\n",
       "2015-02-21 18:14:18 -0800    1\n",
       "2015-02-23 10:42:52 -0800    1\n",
       "2015-02-22 13:06:59 -0800    1\n",
       "2015-02-22 08:35:29 -0800    1\n",
       "2015-02-22 20:08:49 -0800    1\n",
       "Name: tweet_created, Length: 14247, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tweet_created'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eastern Time (US & Canada)    3744\n",
       "Central Time (US & Canada)    1931\n",
       "Pacific Time (US & Canada)    1208\n",
       "Quito                          738\n",
       "Atlantic Time (Canada)         497\n",
       "                              ... \n",
       "Warsaw                           1\n",
       "Solomon Is.                      1\n",
       "America/Detroit                  1\n",
       "West Central Africa              1\n",
       "Istanbul                         1\n",
       "Name: user_timezone, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['user_timezone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JetBlueNews      63\n",
       "kbosspotter      32\n",
       "_mhertz          29\n",
       "otisday          28\n",
       "throthra         27\n",
       "                 ..\n",
       "zbarry1015        1\n",
       "osman_khan        1\n",
       "lalo_haros        1\n",
       "philwa            1\n",
       "travelmanphil     1\n",
       "Name: name, Length: 7701, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet_id',\n",
       " 'airline_sentiment',\n",
       " 'airline_sentiment_confidence',\n",
       " 'negativereason',\n",
       " 'negativereason_confidence',\n",
       " 'airline',\n",
       " 'text',\n",
       " 'tweet_coord',\n",
       " 'tweet_location']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.drop('negativereason_gold', axis=1, inplace=True)\n",
    "tweets.drop('airline_sentiment_gold', axis=1, inplace=True)\n",
    "tweets.drop('retweet_count', axis=1, inplace=True)\n",
    "tweets.drop('tweet_created', axis=1, inplace=True)\n",
    "tweets.drop('user_timezone', axis=1, inplace=True)\n",
    "tweets.drop('name', axis=1, inplace=True)\n",
    "\n",
    "#current list of columns\n",
    "list(tweets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000    10445\n",
       "0.6667       71\n",
       "0.6632       35\n",
       "0.6559       30\n",
       "0.6596       30\n",
       "          ...  \n",
       "0.3913        1\n",
       "0.7273        1\n",
       "0.6353        1\n",
       "0.6260        1\n",
       "0.3544        1\n",
       "Name: airline_sentiment_confidence, Length: 1023, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['airline_sentiment_confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Service Issue         2910\n",
       "Late Flight                    1665\n",
       "Can't Tell                     1190\n",
       "Cancelled Flight                847\n",
       "Lost Luggage                    724\n",
       "Bad Flight                      580\n",
       "Flight Booking Problems         529\n",
       "Flight Attendant Complaints     481\n",
       "longlines                       178\n",
       "Damaged Luggage                  74\n",
       "Name: negativereason, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['negativereason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000    3436\n",
       "0.0000    1344\n",
       "0.6667      62\n",
       "0.6632      33\n",
       "0.6596      29\n",
       "          ... \n",
       "0.3386       1\n",
       "0.3577       1\n",
       "0.3249       1\n",
       "0.3290       1\n",
       "0.3255       1\n",
       "Name: negativereason_confidence, Length: 1410, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['negativereason_confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]                      164\n",
       "[40.64656067, -73.78334045]       6\n",
       "[32.91792297, -97.00367737]       3\n",
       "[40.64646912, -73.79133606]       3\n",
       "[37.78618135, -122.45742542]      2\n",
       "                               ... \n",
       "[37.77414482, -122.43628588]      1\n",
       "[25.8058675, -80.1260541]         1\n",
       "[36.11159761, -86.7844525]        1\n",
       "[19.43706642, -99.07927123]       1\n",
       "[34.02761838, -118.49646336]      1\n",
       "Name: tweet_coord, Length: 832, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tweet_coord'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boston, MA                 157\n",
       "New York, NY               156\n",
       "Washington, DC             150\n",
       "New York                   127\n",
       "USA                        126\n",
       "                          ... \n",
       "Raising Through 7            1\n",
       "Orange County, USA           1\n",
       "Rochester, Michigan          1\n",
       "New York, NY | Brooklyn      1\n",
       "Valrico, Florida             1\n",
       "Name: tweet_location, Length: 3081, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tweet_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.drop('tweet_id', axis=1, inplace=True)\n",
    "# tweets['name'].value_counts()\n",
    "# tweets['name'].value_counts()\n",
    "# tweets['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets[tweets['airline_sentiment_confidence'] > 0.80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10459, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10459 entries, 0 to 14638\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      10459 non-null  int64  \n",
      " 1   airline_sentiment             10459 non-null  object \n",
      " 2   airline_sentiment_confidence  10459 non-null  float64\n",
      " 3   negativereason                7392 non-null   object \n",
      " 4   negativereason_confidence     7396 non-null   float64\n",
      " 5   airline                       10459 non-null  object \n",
      " 6   text                          10459 non-null  object \n",
      " 7   tweet_coord                   746 non-null    object \n",
      " 8   tweet_location                7007 non-null   object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 817.1+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just in case\n",
    "def labels_to_num(label):\n",
    "    if label == 'negative':\n",
    "        label = 0\n",
    "    elif label == 'positive':\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['airline_sentiment_num'] = tweets['airline_sentiment'].map(labels_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7392\n",
       "2    1550\n",
       "1    1517\n",
       "Name: airline_sentiment_num, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['airline_sentiment_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Translate nltk POS to wordnet tags for lemmatizer\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() #lemmatizing\n",
    "#STOPWORDS\n",
    "\n",
    "def process_text(text):\n",
    "    doc = text.lower()\n",
    "    doc = re.sub(r'@\\w+', '', doc) # Remove @s\n",
    "    doc = re.sub(r'#', '', doc) # Remove hashtags\n",
    "    doc = re.sub(r':', ' ', emoji.demojize(doc)) # Turn emojis into words\n",
    "    doc = re.sub(r'http\\S+', '',doc) # Remove URLs\n",
    "    doc = re.sub(r'\\$\\S+', 'dollar', doc) # Change dollar amounts to dollar\n",
    "    doc = re.sub(r'[^a-z0-9\\s]', '', doc) # Remove punctuation\n",
    "    doc = re.sub(r'[0-9]+', 'number', doc) # Change number values to number\n",
    "    \n",
    "    doc = word_tokenize(doc)\n",
    "#     doc = [word for word in doc if word not in sw]\n",
    "   \n",
    "    \n",
    "    doc = pos_tag(doc)\n",
    "\n",
    "    doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "\n",
    "    doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc] \n",
    "\n",
    "    return ' '.join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['processed_text'] = tweets['text'].map(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica What @dhepburn said.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what say'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['processed_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummied_airlines = pd.get_dummies(tweets['airline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets.join(dummied_airlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline', 'text',\n",
       "       'tweet_coord', 'tweet_location', 'airline_sentiment_num',\n",
       "       'processed_text', 'American', 'Delta', 'Southwest', 'US Airways',\n",
       "       'United', 'Virgin America'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets.drop(columns=['tweet_id', 'airline_sentiment_confidence', 'airline',\n",
    "       'negativereason', 'negativereason_confidence', 'text', 'tweet_coord', 'tweet_location', 'airline_sentiment_num', 'airline_sentiment'], axis =1)\n",
    "y = tweets['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##running our train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try different parameters\n",
    "vectorizer = TfidfVectorizer(input='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "sparse_out = vectorizer.fit_transform(X_train['processed_text'])\n",
    "tfidf_df_train = pd.DataFrame(data = sparse_out.toarray(),\n",
    "                        columns = vectorizer.get_feature_names(), index = X_train.index)\n",
    "\n",
    "\n",
    "X_train.drop(['processed_text'], axis=1, inplace = True)\n",
    "X_train_vec = X_train.join(tfidf_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "sparse_out1 = vectorizer.transform(X_test['processed_text'])\n",
    "tfidf_df_test = pd.DataFrame(data = sparse_out1.toarray(),\n",
    "                        columns = vectorizer.get_feature_names(), index = X_test.index)\n",
    "\n",
    "X_test.drop(['processed_text'], axis=1, inplace = True)\n",
    "X_test_vec = X_test.join(tfidf_df_test)\n",
    "X_test_vec = X_test_vec.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoteN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    7392\n",
       "neutral     1550\n",
       "positive    1517\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8367, 8782)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2092, 8782)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.548342249273549\n"
     ]
    }
   ],
   "source": [
    "##checking our dummy/base model score\n",
    "dc = DummyClassifier(strategy='stratified')\n",
    "dc.fit(X_train_vec, y_train)\n",
    "\n",
    "print(cross_val_score(dc, X_train_vec, y_train).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done   2 out of   5 | elapsed: 11.0min remaining: 16.5min\n",
      "[Parallel(n_jobs=-4)]: Done   5 out of   5 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8355443579630378\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC() #Grid search ()\n",
    "svc.fit(X_train_vec, y_train)\n",
    "\n",
    "print(cross_val_score(svc, X_train_vec, y_train, n_jobs=-4, verbose=3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-4)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done   2 out of   5 | elapsed:   37.0s remaining:   55.6s\n",
      "[Parallel(n_jobs=-4)]: Done   5 out of   5 | elapsed:   38.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656628824802667\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression() #max iterations-change; l2 or l1 - Grid search (l1, l2, C=[.1, 1, 10])  # Suppose .1 is best, then for Round #2 C=[.03, .1, .3\n",
    "lr.fit(X_train_vec, y_train)\n",
    "print(cross_val_score(lr, X_train_vec, y_train, n_jobs=-4, verbose=3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= lr.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train= lr.predict(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925660332257679"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.880019120458891"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done   2 out of   5 | elapsed:    2.3s remaining:    3.4s\n",
      "[Parallel(n_jobs=-4)]: Done   5 out of   5 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7422002126685621\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vec, y_train)\n",
    "print(cross_val_score(nb, X_train_vec, y_train, n_jobs=-4, verbose=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Configurations and Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Twitter={}\n",
    "Twitter['Consumer Key'] = 'iAimqbAdWiBrUfXe0Xmuhlyps'\n",
    "Twitter['Consumer Secret'] = 'YWUyAsX8sA2VuJCwQv4x3MUhAGmm48VlV0ZTx2yWNWqlGCP9Kj'\n",
    "Twitter['Access Token'] = '54188780-kRmlqKRHleSb1WBBTfrj4CR57wLxJYuU5qH9piYlq'\n",
    "Twitter['Access Token Secret'] = 'JXzf6VKWIFhVhAuIYWWQX04jCaHgfgjia77ARpK7v1Z3p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (1.19.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x0000022D8AFAC4C0>\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "\n",
    "auth = twitter.oauth.OAuth(Twitter['Access Token'],\n",
    "                           Twitter['Access Token Secret'],\n",
    "                           Twitter['Consumer Key'],\n",
    "                           Twitter['Consumer Secret'])\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_list = tweets.columns[-6:].tolist()\n",
    "airlines_dict = {i: '#'+i.replace(' ', '') for i in airlines_list }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'American': '#American',\n",
       " 'Delta': '#Delta',\n",
       " 'Southwest': '#Southwest',\n",
       " 'US Airways': '#USAirways',\n",
       " 'United': '#United',\n",
       " 'Virgin America': '#VirginAmerica'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_dict['American'] = '#AmericanAirlines'\n",
    "airlines_dict['United'] = '#UnitedAirlines'\n",
    "airlines_dict['Southwest'] = '#SouthwestAirlines'\n",
    "airlines_dict['Delta'] = '#DeltaAirlines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tweets(hashtag, number):\n",
    "    list_of_tweets =[]\n",
    "    list_of_dirty_tweets =[]\n",
    "    search_results = twitter_api.search.tweets(q=hashtag, count=number)\n",
    "    print(hashtag + ':' + str(len(search_results['statuses'])) + \"\\n\")\n",
    "    for num in range(len(search_results['statuses'])):\n",
    "        list_of_tweets.append(process_text(search_results['statuses'][num]['text']))\n",
    "        list_of_dirty_tweets.append(search_results['statuses'][num]['text'])\n",
    "        \n",
    "    return list_of_tweets, list_of_dirty_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'American': '#AmericanAirlines',\n",
       " 'Delta': '#DeltaAirlines',\n",
       " 'Southwest': '#SouthwestAirlines',\n",
       " 'US Airways': '#USAirways',\n",
       " 'United': '#UnitedAirlines',\n",
       " 'Virgin America': '#VirginAmerica'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#AmericanAirlines:100\n",
      "\n",
      "#DeltaAirlines:100\n",
      "\n",
      "#SouthwestAirlines:100\n",
      "\n",
      "#USAirways:4\n",
      "\n",
      "#UnitedAirlines:100\n",
      "\n",
      "#VirginAmerica:11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_real_by_airline = {}\n",
    "for column_name, hashtag  in airlines_dict.items():\n",
    "    X_real_one_airline = pd.DataFrame(get_tweets(hashtag, 1000)[0], columns=['processed_text'])\n",
    "    for other_col_name in airlines_dict.keys():\n",
    "        if other_col_name == column_name:\n",
    "            X_real_one_airline[column_name] = 1\n",
    "        else:\n",
    "            X_real_one_airline[other_col_name] = 0\n",
    "            \n",
    "    X_real_by_airline[column_name] = X_real_one_airline\n",
    "    \n",
    "    \n",
    "#X_real = pd.DataFrame(get_tweets('#DeltaAirlines', 7), columns=['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_out2 = vectorizer.transform(X_real_by_airline['Delta']['processed_text'])\n",
    "tfidf_df_real = pd.DataFrame(data = sparse_out2.toarray(),\n",
    "                        columns = vectorizer.get_feature_names(), index = X_real_by_airline['Delta'].index)\n",
    "\n",
    "\n",
    "X_real_by_airline['Delta'].drop(['processed_text'], axis=1, inplace = True)\n",
    "X_real_vec = X_real_by_airline['Delta'].join(tfidf_df_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = lr.predict(X_real_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0    neutral\n",
       "1    neutral\n",
       "2   negative\n",
       "3    neutral\n",
       "4    neutral\n",
       "..       ...\n",
       "95  negative\n",
       "96  negative\n",
       "97  negative\n",
       "98   neutral\n",
       "99  positive\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(pd.DataFrame(preds), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '#Southwest' \n",
    "\n",
    "number = 10\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text(search_results['statuses'][9]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
